import org.apache.spark.sql.SparkSession
val spark=SparkSession.builder.appName("gani").getOrCreate()
val data=sc.textFile("data.csv")
val rdd=data.map(x=>x.split(","))
val rdd1 = rdd.map(x=> x(13))   (or) val rdd1=rdd.map(_.slice(13,14)) 
rdd1.collect()
val rdd2 = rdd1.map(x=>(x,1))
val rdd3 = rdd2.reduceByKey((x,y) => x+y)
val count_mom=rdd3.map( x => x.swap).sortByKey(false)
count_mom.take(5)
val top5 = sc.parallelize(count_mom.take(5))
top5.coalesce(1).saveAsTextFile("IPLData")